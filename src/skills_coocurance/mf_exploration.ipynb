{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from time import time\n",
    "from typing import List\n",
    "\n",
    "from dfply import *\n",
    "import torch\n",
    "# from torch.autograd import Variable\n",
    "# PyTorch TensorBoard support\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_EXAMPLES = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vacancy_id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>presentation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Tax planning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Xero</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>communication</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>administrative tasks</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   vacancy_id                 title\n",
       "0           1          presentation\n",
       "1           1          Tax planning\n",
       "2           1                  Xero\n",
       "3           1         communication\n",
       "4           2  administrative tasks"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vac_skills = pd.read_csv('../../data/skills_coocurrance/seek_vacancies.csv') >> head(MAX_EXAMPLES)\n",
    "vac_skills.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resume_id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Auto Insurance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>DETAIL-ORIENTED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>MICROSOFT OFFICE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>REAL ESTATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>ACROBAT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   resume_id             title\n",
       "0          1    Auto Insurance\n",
       "1          2   DETAIL-ORIENTED\n",
       "2          2  MICROSOFT OFFICE\n",
       "3          3       REAL ESTATE\n",
       "4          3           ACROBAT"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_skills = pd.read_csv('../../data/skills_coocurrance/indeed_resumes.csv') >> head(MAX_EXAMPLES)\n",
    "res_skills.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_clean(text):\n",
    "    '''\n",
    "    Removes default bad characters\n",
    "    '''\n",
    "    if not (pd.isnull(text)):\n",
    "#         # text = filter(lambda x: x in string.printable, text)\n",
    "#         bad_chars = set([\"@\", \"+\", '/', \"'\", '\"', '\\\\','(',')', '', '\\\\n', '', '?', '#', ',','.', '[',']', '%', '$', '&', ';', '!', ';', ':',\"*\", \"_\", \"=\", \"}\", \"{\"])\n",
    "#         for char in bad_chars:\n",
    "#             text = text.replace(char, \" \")\n",
    "#         text = re.sub('\\d+', \"\", text)\n",
    "        text = text.lower()\n",
    "        text = re.sub('[^A-Za-z]', ' ', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gr_id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>128975</td>\n",
       "      <td>project management</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>128975</td>\n",
       "      <td>blueprints</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>128975</td>\n",
       "      <td>schematics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>128975</td>\n",
       "      <td>autocad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>128975</td>\n",
       "      <td>autodesk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        gr_id               title\n",
       "99995  128975  project management\n",
       "99996  128975          blueprints\n",
       "99997  128975          schematics\n",
       "99998  128975             autocad\n",
       "99999  128975            autodesk"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_vac_rows = vac_skills.shape[0]\n",
    "vacancies = vac_skills >> mutate(gr_id = X.vacancy_id) >> select(X.gr_id, X.title)\n",
    "resumes = res_skills >> mutate(gr_id = X.resume_id + n_vac_rows) >> select(X.gr_id, X.title)\n",
    "\n",
    "skill_groups = (vacancies >>\n",
    "     bind_rows(resumes) >> \n",
    "     mutate(title = X.title.map(lambda x: str(x).lower()))\n",
    "    )\n",
    "\n",
    "skill_groups >> tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gr_id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>presentation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>tax planning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>xero</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>communication</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>administrative tasks</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gr_id                 title\n",
       "0      1          presentation\n",
       "1      1          tax planning\n",
       "2      1                  xero\n",
       "3      1         communication\n",
       "4      2  administrative tasks"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Analysis of the skills frequencies\n",
    "#freq_skills = skill_groups.groupby('title').aggregate(lambda x: len(x))\n",
    "#freq_skills = skill_groups >> group_by(X.title) >> summarize(freq = n(X.gr_id)) # >> arrange(desc(X.freq))\n",
    "#freq_skills = skill_groups >> group_by(X.title) >> summarize(freq = n(X.gr_id)) # >> arrange(desc(X.freq))\n",
    "#(freq_skills >> mask(X.gr_id > 10) \n",
    "#     >> mutate(title_len = X.title.map(lambda t: len(t)))\n",
    "#     >> mask(len(X.title_len) > 1) \n",
    "#     >> head()\n",
    "# )\n",
    "df_titles_cnt = pd.DataFrame(\n",
    "    skill_groups.groupby('title').size(),\n",
    "    columns=['count']\n",
    ")\n",
    "df_titles_cnt.head()\n",
    "popular_skills  = list(set(df_titles_cnt.query('count >= 10').index))\n",
    "skills_filter = skill_groups.title.isin(popular_skills)\n",
    "\n",
    "df_groups_cnt = pd.DataFrame(\n",
    "    skill_groups.groupby('gr_id').size(),\n",
    "    columns=['count']\n",
    ")\n",
    "active_groups = list(set(df_groups_cnt.query('count >= 3').index))\n",
    "groups_filter =  skill_groups.gr_id.isin(active_groups)\n",
    "\n",
    "freq_skill_groups = skill_groups[skills_filter & groups_filter]\n",
    "freq_skill_groups >> head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(133790, 2)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_skill_groups.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1991, 2)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_titles_cnt['title'] = df_titles_cnt.index\n",
    "df_titles_cnt.reset_index(level=0, drop=True, inplace=True)\n",
    "df_titles_cnt.head()\n",
    "popular_skills = df_titles_cnt.query('count > 10')\n",
    "popular_skills.shape\n",
    "#freq_skill_groups.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gr_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(presentation, tax planning, xero, communication)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(administrative tasks, administrative, physica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(servicing, maintenance, repairs)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(full class 1 license, physically fit, grooming)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(team player,)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title\n",
       "gr_id                                                   \n",
       "1      (presentation, tax planning, xero, communication)\n",
       "2      (administrative tasks, administrative, physica...\n",
       "3                      (servicing, maintenance, repairs)\n",
       "5       (full class 1 license, physically fit, grooming)\n",
       "6                                         (team player,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skills_lists_df = freq_skill_groups.groupby('gr_id').aggregate(lambda x: tuple(x))\n",
    "skills_lists_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 219 µs, sys: 0 ns, total: 219 µs\n",
      "Wall time: 219 µs\n"
     ]
    }
   ],
   "source": [
    "%time skills_multilist = skills_lists_df['title'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>llm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   llm\n",
       "0  3.2"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max_skills = 0\n",
    "# for skills in texts_multilist:\n",
    "#     max_skills = max(len(skills), max_skills)\n",
    "# print(max_skills)\n",
    "@make_symbolic\n",
    "def vlen(xv):\n",
    "    return xv.map(lambda x: len(x))\n",
    "\n",
    "(skills_lists_df >> mutate(llen = vlen(X.title)) >> head()\n",
    "    >>  summarize(llm = mean(X.llen))\n",
    ") >> head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = []\n",
    "for sentence in skills_multilist:\n",
    "    for token in sentence:\n",
    "        if token not in vocabulary:\n",
    "            vocabulary.append(token)\n",
    "\n",
    "word2idx = {w: idx for (idx, w) in enumerate(vocabulary)}\n",
    "idx2word = {idx: w for (idx, w) in enumerate(vocabulary)}\n",
    "\n",
    "vocabulary_size = len(vocabulary)\n",
    "\n",
    "# print(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "skill_group_lookup = {v: i+1 for i, v in enumerate(freq_skill_groups['gr_id'].unique())}\n",
    "skill_lookup = {v: i+1 for i, v in enumerate(freq_skill_groups['title'].unique())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class SkillGroupToSkillLevelDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, skill_lookup:dict, skill_group_lookup:dict):\n",
    "        self.df = df\n",
    "        self.skill_lookup = skill_lookup\n",
    "        self.skill_group_lookup = skill_group_lookup\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "        skill_group_id = self.skill_group_lookup[row.gr_id]\n",
    "        skill_id = self.skill_lookup[row.title]\n",
    "        \n",
    "        #as we do not have means to measure the rating let's it be 1\n",
    "        rating = torch.tensor(1.0, dtype=torch.float32)\n",
    "        #input is tuple (skill_group_id, skill if) value is rating 1 \n",
    "        return (skill_group_id, skill_id), rating\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "skill_groups = freq_skill_groups['gr_id'].unique()\n",
    "train_skill_groups, validate_skill_groups = train_test_split(skill_groups, test_size=0.2)\n",
    "\n",
    "freq_skill_groups_train = freq_skill_groups[freq_skill_groups['gr_id'].isin(train_skill_groups)]\n",
    "freq_skill_groups_valid = freq_skill_groups[freq_skill_groups['gr_id'].isin(validate_skill_groups)]\n",
    "\n",
    "train_ds = SkillGroupToSkillLevelDataset(freq_skill_groups_train, skill_lookup, skill_group_lookup)\n",
    "valid_ds = SkillGroupToSkillLevelDataset(freq_skill_groups_valid, skill_lookup, skill_group_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class MfDotBias(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self, n_factors, n_skill_groups, n_skills, ratings_range=None, use_biases=True\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.bias = use_biases\n",
    "        self.y_range = ratings_range\n",
    "        self.user_embedding = nn.Embedding(n_skill_groups+1, n_factors, padding_idx=0)\n",
    "        self.item_embedding = nn.Embedding(n_skills+1, n_factors, padding_idx=0)\n",
    "\n",
    "        if use_biases:\n",
    "            self.user_bias = nn.Embedding(n_skill_groups+1, 1, padding_idx=0)\n",
    "            self.item_bias = nn.Embedding(n_skills+1, 1, padding_idx=0)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        sk_groups, skills = inputs\n",
    "        dot = self.user_embedding(sk_groups) * self.item_embedding(skills)\n",
    "        result = dot.sum(1)\n",
    "        if self.bias:\n",
    "            result = (\n",
    "                result + self.user_bias(sk_groups).squeeze() + self.item_bias(skills).squeeze()\n",
    "            )\n",
    "\n",
    "        if self.y_range is None:\n",
    "            return result\n",
    "        else:\n",
    "            return (\n",
    "                torch.sigmoid(result) * (self.y_range[1] - self.y_range[0])\n",
    "                + self.y_range[0]\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 277,618 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "model = MfDotBias(10, len(skill_group_lookup), len(skill_lookup))\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cpu\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using device %s\" %device)\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch_index: int, train_loader: DataLoader, loss_fn: nn.MSELoss, device: torch.device, \n",
    "    optimizer: optim.Optimizer, tb_writer: SummaryWriter):\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "\n",
    "    # Here, we use enumerate(training_loader) instead of\n",
    "    # iter(training_loader) so that we can track the batch\n",
    "    # index and do some intra-epoch reporting\n",
    "    for i, data in tqdm(enumerate(train_loader)):\n",
    "        # Every data instance is an input + label pair\n",
    "        inputs, labels = data\n",
    "        (sk_gr, sk) = inputs\n",
    "        inputs_d = (sk_gr.to(device), sk.to(device))\n",
    "        labels_d= labels.to(device)\n",
    "\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        outputs = model(inputs_d)\n",
    "\n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn(outputs, labels_d)\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:\n",
    "            last_loss = running_loss / 1000 # loss per batch\n",
    "            print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
    "            tb_x = epoch_index * len(train_loader) + i + 1\n",
    "            tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
    "            running_loss = 0.\n",
    "\n",
    "    return last_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "835it [00:14, 57.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.0 valid 4.53495979309082\n",
      "EPOCH 2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "835it [00:14, 58.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.0 valid 4.267282962799072\n",
      "EPOCH 3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "835it [00:15, 55.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.0 valid 4.041991710662842\n",
      "EPOCH 4:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "835it [00:14, 59.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.0 valid 3.852346658706665\n",
      "EPOCH 5:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "835it [00:14, 59.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.0 valid 3.6911094188690186\n",
      "EPOCH 6:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "835it [00:14, 56.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.0 valid 3.552428960800171\n",
      "EPOCH 7:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "835it [00:14, 58.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.0 valid 3.434316396713257\n",
      "EPOCH 8:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "835it [00:14, 57.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.0 valid 3.332566738128662\n",
      "EPOCH 9:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "835it [00:14, 56.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.0 valid 3.2450294494628906\n",
      "EPOCH 10:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "835it [00:14, 57.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.0 valid 3.1687891483306885\n",
      "EPOCH 11:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "835it [00:14, 57.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.0 valid 3.1028175354003906\n",
      "EPOCH 12:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "835it [00:14, 55.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.0 valid 3.045154333114624\n",
      "EPOCH 13:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "835it [00:14, 58.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.0 valid 2.99471116065979\n",
      "EPOCH 14:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "835it [00:14, 57.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.0 valid 2.950429916381836\n",
      "EPOCH 15:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "835it [00:15, 55.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.0 valid 2.911378860473633\n",
      "EPOCH 16:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "835it [00:14, 57.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.0 valid 2.8771631717681885\n",
      "EPOCH 17:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "835it [00:14, 56.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.0 valid 2.84496808052063\n",
      "EPOCH 18:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "835it [00:14, 57.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.0 valid 2.820000410079956\n",
      "EPOCH 19:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "835it [00:14, 57.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.0 valid 2.793931245803833\n",
      "EPOCH 20:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "835it [00:14, 57.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.0 valid 2.7710020542144775\n"
     ]
    }
   ],
   "source": [
    "#device\n",
    "# Initializing in a separate cell so we can easily add more epochs to the same run\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "tb_summary_writer = SummaryWriter('../../tensorboard/runs/matrix_decomposition_trainer_{}'.format(timestamp))\n",
    "epoch_number = 0\n",
    "\n",
    "EPOCHS = 20\n",
    "\n",
    "best_vloss = 1_000_000.\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print('EPOCH {}:'.format(epoch_number + 1))\n",
    "\n",
    "    # Make sure gradient tracking is on, and do a pass over the data\n",
    "    model.train(True)\n",
    "    avg_loss = train_one_epoch(epoch_number, train_dl, criterion, device, optimizer, tb_summary_writer)\n",
    "\n",
    "    # We don't need gradients on to do reporting\n",
    "    model.train(False)\n",
    "\n",
    "    running_vloss = 0.0\n",
    "    for i, vdata in enumerate(valid_dl):\n",
    "        vinputs, vlabels = vdata\n",
    "        voutputs = model(vinputs)\n",
    "        vloss = criterion(voutputs, vlabels)\n",
    "        running_vloss += vloss\n",
    "\n",
    "    avg_vloss = running_vloss / (i + 1)\n",
    "    print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
    "\n",
    "    # Log the running loss averaged per batch\n",
    "    # for both training and validation\n",
    "    tb_summary_writer.add_scalars('Training vs. Validation Loss',\n",
    "                    { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
    "                    epoch_number + 1)\n",
    "    tb_summary_writer.flush()\n",
    "\n",
    "    # Track best performance, and save the model's state\n",
    "    if avg_vloss < best_vloss:\n",
    "        best_vloss = avg_vloss\n",
    "        model_path = '../../models/skills_adj_matrix/model_{}_{}'.format(timestamp, epoch_number)\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    epoch_number += 1"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f61926e1a4991f233528a616693af481fc024f683e759f03e3029b66e813f45a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('SkillsTaxonomyPipe-uwPg1jZG': pipenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
