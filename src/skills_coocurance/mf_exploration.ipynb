{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from time import time\n",
    "from typing import List\n",
    "\n",
    "from dfply import *\n",
    "import torch\n",
    "# from torch.autograd import Variable\n",
    "# PyTorch TensorBoard support\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_EXAMPLES = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vacancy_id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>presentation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Tax planning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Xero</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>communication</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>administrative tasks</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   vacancy_id                 title\n",
       "0           1          presentation\n",
       "1           1          Tax planning\n",
       "2           1                  Xero\n",
       "3           1         communication\n",
       "4           2  administrative tasks"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vac_skills = pd.read_csv('../../data/skills_coocurrance/seek_vacancies.csv') >> head(MAX_EXAMPLES)\n",
    "vac_skills.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resume_id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Auto Insurance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>DETAIL-ORIENTED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>MICROSOFT OFFICE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>REAL ESTATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>ACROBAT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   resume_id             title\n",
       "0          1    Auto Insurance\n",
       "1          2   DETAIL-ORIENTED\n",
       "2          2  MICROSOFT OFFICE\n",
       "3          3       REAL ESTATE\n",
       "4          3           ACROBAT"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_skills = pd.read_csv('../../data/skills_coocurrance/indeed_resumes.csv') >> head(MAX_EXAMPLES)\n",
    "res_skills.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_clean(text):\n",
    "    '''\n",
    "    Removes default bad characters\n",
    "    '''\n",
    "    if not (pd.isnull(text)):\n",
    "#         # text = filter(lambda x: x in string.printable, text)\n",
    "#         bad_chars = set([\"@\", \"+\", '/', \"'\", '\"', '\\\\','(',')', '', '\\\\n', '', '?', '#', ',','.', '[',']', '%', '$', '&', ';', '!', ';', ':',\"*\", \"_\", \"=\", \"}\", \"{\"])\n",
    "#         for char in bad_chars:\n",
    "#             text = text.replace(char, \" \")\n",
    "#         text = re.sub('\\d+', \"\", text)\n",
    "        text = text.lower()\n",
    "        text = re.sub('[^A-Za-z]', ' ', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gr_id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>13008</td>\n",
       "      <td>ms office, windows &amp; database software</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>13008</td>\n",
       "      <td>retail sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>13008</td>\n",
       "      <td>branding, sales &amp; marketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>13008</td>\n",
       "      <td>accounting &amp; finance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>13008</td>\n",
       "      <td>csr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      gr_id                                   title\n",
       "9995  13008  ms office, windows & database software\n",
       "9996  13008                            retail sales\n",
       "9997  13008             branding, sales & marketing\n",
       "9998  13008                    accounting & finance\n",
       "9999  13008                                     csr"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_vac_rows = vac_skills.shape[0]\n",
    "vacancies = vac_skills >> mutate(gr_id = X.vacancy_id) >> select(X.gr_id, X.title)\n",
    "resumes = res_skills >> mutate(gr_id = X.resume_id + n_vac_rows) >> select(X.gr_id, X.title)\n",
    "\n",
    "skill_groups = (vacancies >>\n",
    "     bind_rows(resumes) >> \n",
    "     mutate(title = X.title.map(lambda x: str(x).lower()))\n",
    "    )\n",
    "\n",
    "skill_groups >> tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gr_id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>presentation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>xero</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>communication</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>physically fit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>verbal and written</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gr_id               title\n",
       "0      1        presentation\n",
       "2      1                xero\n",
       "3      1       communication\n",
       "7      2      physically fit\n",
       "9      2  verbal and written"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Analysis of the skills frequencies\n",
    "#freq_skills = skill_groups.groupby('title').aggregate(lambda x: len(x))\n",
    "#freq_skills = skill_groups >> group_by(X.title) >> summarize(freq = n(X.gr_id)) # >> arrange(desc(X.freq))\n",
    "#freq_skills = skill_groups >> group_by(X.title) >> summarize(freq = n(X.gr_id)) # >> arrange(desc(X.freq))\n",
    "#(freq_skills >> mask(X.gr_id > 10) \n",
    "#     >> mutate(title_len = X.title.map(lambda t: len(t)))\n",
    "#     >> mask(len(X.title_len) > 1) \n",
    "#     >> head()\n",
    "# )\n",
    "df_titles_cnt = pd.DataFrame(\n",
    "    skill_groups.groupby('title').size(),\n",
    "    columns=['count']\n",
    ")\n",
    "df_titles_cnt.head()\n",
    "popular_skills  = list(set(df_titles_cnt.query('count >= 10').index))\n",
    "skills_filter = skill_groups.title.isin(popular_skills)\n",
    "\n",
    "df_groups_cnt = pd.DataFrame(\n",
    "    skill_groups.groupby('gr_id').size(),\n",
    "    columns=['count']\n",
    ")\n",
    "active_groups = list(set(df_groups_cnt.query('count >= 3').index))\n",
    "groups_filter =  skill_groups.gr_id.isin(active_groups)\n",
    "\n",
    "freq_skill_groups = skill_groups[skills_filter & groups_filter]\n",
    "freq_skill_groups >> head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9496, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_skill_groups.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(274, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_titles_cnt['title'] = df_titles_cnt.index\n",
    "df_titles_cnt.reset_index(level=0, drop=True, inplace=True)\n",
    "df_titles_cnt.head()\n",
    "popular_skills = df_titles_cnt.query('count > 10')\n",
    "popular_skills.shape\n",
    "#freq_skill_groups.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gr_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(presentation, xero, communication)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(physically fit, verbal and written)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(physically fit,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(team player,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(communication, welding)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      title\n",
       "gr_id                                      \n",
       "1       (presentation, xero, communication)\n",
       "2      (physically fit, verbal and written)\n",
       "5                         (physically fit,)\n",
       "6                            (team player,)\n",
       "8                  (communication, welding)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skills_lists_df = freq_skill_groups.groupby('gr_id').aggregate(lambda x: tuple(x))\n",
    "skills_lists_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 181 µs, sys: 40 µs, total: 221 µs\n",
      "Wall time: 218 µs\n"
     ]
    }
   ],
   "source": [
    "%time skills_multilist = skills_lists_df['title'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>llm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   llm\n",
       "0  1.8"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max_skills = 0\n",
    "# for skills in texts_multilist:\n",
    "#     max_skills = max(len(skills), max_skills)\n",
    "# print(max_skills)\n",
    "@make_symbolic\n",
    "def vlen(xv):\n",
    "    return xv.map(lambda x: len(x))\n",
    "\n",
    "(skills_lists_df >> mutate(llen = vlen(X.title)) >> head()\n",
    "    >>  summarize(llm = mean(X.llen))\n",
    ") >> head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = []\n",
    "for sentence in skills_multilist:\n",
    "    for token in sentence:\n",
    "        if token not in vocabulary:\n",
    "            vocabulary.append(token)\n",
    "\n",
    "word2idx = {w: idx for (idx, w) in enumerate(vocabulary)}\n",
    "idx2word = {idx: w for (idx, w) in enumerate(vocabulary)}\n",
    "\n",
    "vocabulary_size = len(vocabulary)\n",
    "\n",
    "# print(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "skill_group_lookup = {v: i+1 for i, v in enumerate(freq_skill_groups['gr_id'].unique())}\n",
    "skill_lookup = {v: i+1 for i, v in enumerate(freq_skill_groups['title'].unique())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class SkillGroupToSkillLevelDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, skill_lookup:dict, skill_group_lookup:dict):\n",
    "        self.df = df\n",
    "        self.skill_lookup = skill_lookup\n",
    "        self.skill_group_lookup = skill_group_lookup\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "        skill_group_id = self.skill_group_lookup[row.gr_id]\n",
    "        skill_id = self.skill_lookup[row.title]\n",
    "        \n",
    "        #as we do not have means to measure the rating let's it be 1\n",
    "        rating = torch.tensor(1.0, dtype=torch.float32)\n",
    "        #input is tuple (skill_group_id, skill if) value is rating 1 \n",
    "        return (skill_group_id, skill_id), rating\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3481/3508729061.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"is_valid\"] = False\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def get_rand_n_skills_by_skill_group(\n",
    "    df, n_samples, min_skills_in_sk_gr=1, skill_group_colname=\"gr_id\"\n",
    "):\n",
    "    return (\n",
    "        df.groupby(skill_group_colname)\n",
    "        .filter(lambda x: len(x) >= min_skills_in_sk_gr)\n",
    "        .groupby(skill_group_colname)\n",
    "        .sample(n = n_samples, replace=True)\n",
    "        .sort_values(skill_group_colname)\n",
    "    )\n",
    "\n",
    "\n",
    "# tdf = get_rand_n_skills_by_skill_group(freq_skill_groups, 1)\n",
    "# tdf.head()\n",
    "\n",
    "\n",
    "def mark_rand_n_ratings_as_validation_set(\n",
    "    df, n, min_skills_in_sk_gr=1, skill_group_colname=\"gr_id\"\n",
    "):\n",
    "\n",
    "    df[\"is_valid\"] = False\n",
    "    \n",
    "    df.loc[\n",
    "        get_rand_n_skills_by_skill_group(\n",
    "            df,\n",
    "            n,\n",
    "            min_skills_in_sk_gr,\n",
    "            skill_group_colname=skill_group_colname\n",
    "        ).index,\n",
    "        \"is_valid\",\n",
    "    ] = True\n",
    "    return df\n",
    "\n",
    "freq_skill_groups = mark_rand_n_ratings_as_validation_set(freq_skill_groups, 1)\n",
    "\n",
    "freq_skill_groups_train = freq_skill_groups[freq_skill_groups.is_valid==False]\n",
    "freq_skill_groups_valid = freq_skill_groups[freq_skill_groups.is_valid==True]\n",
    "\n",
    "train_ds = SkillGroupToSkillLevelDataset(freq_skill_groups_train, skill_lookup, skill_group_lookup)\n",
    "valid_ds = SkillGroupToSkillLevelDataset(freq_skill_groups_valid, skill_lookup, skill_group_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class MfDotBias(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self, n_factors, n_skill_groups, n_skills, ratings_range=None, use_biases=True\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.bias = use_biases\n",
    "        self.y_range = ratings_range\n",
    "        self.user_embedding = nn.Embedding(n_skill_groups+1, n_factors, padding_idx=0)\n",
    "        self.item_embedding = nn.Embedding(n_skills+1, n_factors, padding_idx=0)\n",
    "\n",
    "        if use_biases:\n",
    "            self.user_bias = nn.Embedding(n_skill_groups+1, 1, padding_idx=0)\n",
    "            self.item_bias = nn.Embedding(n_skills+1, 1, padding_idx=0)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        sk_groups, skills = inputs\n",
    "        dot = self.user_embedding(sk_groups) * self.item_embedding(skills)\n",
    "        result = dot.sum(1)\n",
    "        if self.bias:\n",
    "            result = (\n",
    "                result + self.user_bias(sk_groups).squeeze() + self.item_bias(skills).squeeze()\n",
    "            )\n",
    "\n",
    "        if self.y_range is None:\n",
    "            return result\n",
    "        else:\n",
    "            return (\n",
    "                torch.sigmoid(result) * (self.y_range[1] - self.y_range[0])\n",
    "                + self.y_range[0]\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 353,976 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "model = MfDotBias(128, len(skill_group_lookup), len(skill_lookup), ratings_range=(0,1))\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using device %s\" %device)\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model: MfDotBias, epoch_index: int, train_loader: DataLoader, loss_fn: nn.BCELoss, device: torch.device, \n",
    "    optimizer: optim.Optimizer, tb_writer: SummaryWriter):\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "\n",
    "    # Here, we use enumerate(training_loader) instead of\n",
    "    # iter(training_loader) so that we can track the batch\n",
    "    # index and do some intra-epoch reporting\n",
    "    for i, data in tqdm(enumerate(train_loader)):\n",
    "        # Every data instance is an input + label pair\n",
    "        inputs, labels = data\n",
    "        (sk_gr, sk) = inputs\n",
    "        inputs_d = (sk_gr.to(device), sk.to(device))\n",
    "        labels_d= labels.to(device)\n",
    "\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        outputs = model(inputs_d)\n",
    "\n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn(outputs, labels_d)\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:\n",
    "            last_loss = running_loss / 1000 # loss per batch\n",
    "            print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
    "            tb_x = epoch_index * len(train_loader) + i + 1\n",
    "            tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
    "            running_loss = 0.\n",
    "\n",
    "    return last_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "49it [00:00, 62.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.0 valid 4.622587203979492\n",
      "EPOCH 2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "49it [00:00, 62.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.0 valid 4.596617698669434\n",
      "EPOCH 3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "49it [00:00, 64.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.0 valid 4.5717926025390625\n",
      "EPOCH 4:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "49it [00:00, 67.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.0 valid 4.548688888549805\n",
      "EPOCH 5:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "49it [00:00, 60.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS train 0.0 valid 4.527141094207764\n"
     ]
    }
   ],
   "source": [
    "#device\n",
    "# Initializing in a separate cell so we can easily add more epochs to the same run\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "tb_summary_writer = SummaryWriter('../../tensorboard/runs/matrix_decomposition_trainer_{}'.format(timestamp))\n",
    "epoch_number = 0\n",
    "\n",
    "EPOCHS = 5\n",
    "\n",
    "best_vloss = 1_000_000.\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print('EPOCH {}:'.format(epoch_number + 1))\n",
    "\n",
    "    # Make sure gradient tracking is on, and do a pass over the data\n",
    "    model.train(True)\n",
    "    avg_loss = train_one_epoch(model, epoch_number, train_dl, criterion, device, optimizer, tb_summary_writer)\n",
    "\n",
    "    # We don't need gradients on to do reporting\n",
    "    model.train(False)\n",
    "\n",
    "    running_vloss = 0.0\n",
    "    for i, vdata in enumerate(valid_dl):\n",
    "        (val_sk_gr, val_sk), vlabels = vdata\n",
    "        vinputs_d = (val_sk_gr.to(device), val_sk.to(device))\n",
    "        vlabels_d = vlabels.to(device)\n",
    "        voutputs = model(vinputs_d)\n",
    "        vloss = criterion(voutputs, vlabels_d)\n",
    "        running_vloss += vloss\n",
    "\n",
    "    avg_vloss = running_vloss / (i + 1)\n",
    "    print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
    "\n",
    "    # Log the running loss averaged per batch\n",
    "    # for both training and validation\n",
    "    tb_summary_writer.add_scalars('Training vs. Validation Loss',\n",
    "                    { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
    "                    epoch_number + 1)\n",
    "    tb_summary_writer.flush()\n",
    "\n",
    "    # Track best performance, and save the model's state\n",
    "    if avg_vloss < best_vloss:\n",
    "        best_vloss = avg_vloss\n",
    "        # model_path = '../../models/skills_adj_matrix/model_{}_{}'.format(timestamp, epoch_number)\n",
    "        model_path = '../../models/skills_adj_matrix/model_best'\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    epoch_number += 1"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f61926e1a4991f233528a616693af481fc024f683e759f03e3029b66e813f45a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('SkillsTaxonomyPipe-uwPg1jZG': pipenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
